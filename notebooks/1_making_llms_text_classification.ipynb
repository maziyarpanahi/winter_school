{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maziyarpanahi/notebooks/blob/main/notebooks/1_making_llms_text_classification.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG4e6j6ZFMo1"
      },
      "outputs": [],
      "source": [
        "# Transformers installation\n",
        "! pip install -q transformers datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLzk-IJLFTN8"
      },
      "source": [
        "![Widget inference representing the NER task](https://github.com/huggingface/notebooks/blob/main/examples/images/text_classification.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0VTDxzAFMo2"
      },
      "source": [
        "# Text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIIAG5IBFMo3"
      },
      "source": [
        "Text classification is a common NLP task that assigns a label or class to text. Some of the largest companies run text classification in production for a wide range of practical applications. One of the most popular forms of text classification is sentiment analysis, which assigns a label like üôÇ positive, üôÅ negative, or üòê neutral to a sequence of text.\n",
        "\n",
        "This guide will show you how to:\n",
        "\n",
        "1. Finetune [DistilBERT](https://huggingface.co/distilbert/distilbert-base-uncased) on the [IMDb](https://huggingface.co/datasets/imdb) dataset to determine whether a movie review is positive or negative.\n",
        "2. Use your finetuned model for inference.\n",
        "\n",
        "<Tip>\n",
        "\n",
        "To see all architectures and checkpoints compatible with this task, we recommend checking the [task-page](https://huggingface.co/tasks/text-classification).\n",
        "\n",
        "</Tip>\n",
        "\n",
        "Before you begin, make sure you have all the necessary libraries installed:\n",
        "\n",
        "```bash\n",
        "pip install transformers datasets evaluate accelerate\n",
        "```\n",
        "\n",
        "We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbSOwY7rFMo3"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUDPulm_FMo3"
      },
      "source": [
        "## Load IMDb dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0_UP_vVFMo3"
      },
      "source": [
        "Start by loading the IMDb dataset from the ü§ó Datasets library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PKRxZpJFMo4"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# imdb = load_dataset(\"imdb\")\n",
        "\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "imdb = load_dataset(\"imdb\")\n",
        "\n",
        "def stratified_fraction(ds, label_col=\"label\", frac=0.5, seed=42):\n",
        "    labels = set(ds.unique(label_col))\n",
        "    parts = []\n",
        "    for y in labels:\n",
        "        dsy = ds.filter(lambda x: x[label_col] == y)\n",
        "        n = int(len(dsy) * frac)\n",
        "        parts.append(dsy.shuffle(seed=seed).select(range(n)))\n",
        "    return concatenate_datasets(parts).shuffle(seed=seed)\n",
        "\n",
        "train_50 = stratified_fraction(imdb[\"train\"], frac=0.5, seed=42)\n",
        "test_50  = stratified_fraction(imdb[\"test\"],  frac=0.5, seed=42)\n",
        "\n",
        "print(train_50.features)\n",
        "print(train_50[\"label\"][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB2xtmwEFMo4"
      },
      "source": [
        "Then take a look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dhr10frMFMo4"
      },
      "outputs": [],
      "source": [
        "imdb[\"test\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0glI05mqFMo4"
      },
      "source": [
        "There are two fields in this dataset:\n",
        "\n",
        "- `text`: the movie review text.\n",
        "- `label`: a value that is either `0` for a negative review or `1` for a positive review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmyfKiezFMo4"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZokvnfMJFMo4"
      },
      "source": [
        "The next step is to load a DistilBERT tokenizer to preprocess the `text` field:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OctB3Ck8FMo4"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH8XEGh_FMo4"
      },
      "source": [
        "Create a preprocessing function to tokenize `text` and truncate sequences to be no longer than DistilBERT's maximum input length:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LdD7vicFMo4"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdFJXCd0FMo4"
      },
      "source": [
        "To apply the preprocessing function over the entire dataset, use ü§ó Datasets [map](https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map) function. You can speed up `map` by setting `batched=True` to process multiple elements of the dataset at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zq8nD1YFMo4"
      },
      "outputs": [],
      "source": [
        "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da6u2H8zFMo4"
      },
      "source": [
        "Now create a batch of examples using [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding). It's more efficient to *dynamically pad* the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecPv-z_MFMo4"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSe0n_s2FMo5"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSMdtBHUFMo5"
      },
      "source": [
        "Including a metric during training is often helpful for evaluating your model's performance. You can quickly load a evaluation method with the ü§ó [Evaluate](https://huggingface.co/docs/evaluate/index) library. For this task, load the [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) metric (see the ü§ó Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour) to learn more about how to load and compute a metric):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99uQNGPYFMo5"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p4Wr_kBFMo5"
      },
      "source": [
        "Then create a function that passes your predictions and labels to [compute](https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute) to calculate the accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE2d3c-DFMo5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONH0xAlLFMo5"
      },
      "source": [
        "Your `compute_metrics` function is ready to go now, and you'll return to it when you setup your training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkPwDKsJFMo5"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxwwIGImFMo5"
      },
      "source": [
        "Before you start training your model, create a map of the expected ids to their labels with `id2label` and `label2id`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThYPK8a7FMo5"
      },
      "outputs": [],
      "source": [
        "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zwzbttcFMo5"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "If you aren't familiar with finetuning a model with the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer), take a look at the basic tutorial [here](https://huggingface.co/docs/transformers/main/en/tasks/../training#train-with-pytorch-trainer)!\n",
        "\n",
        "</Tip>\n",
        "\n",
        "You're ready to start training your model now! Load DistilBERT with [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSequenceClassification) along with the number of expected labels, and the label mappings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWEkDSSPFMo5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FRbef1YFMo5"
      },
      "source": [
        "At this point, only three steps remain:\n",
        "\n",
        "1. Define your training hyperparameters in [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments). The only required parameter is `output_dir` which specifies where to save your model. You'll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) will evaluate the accuracy and save the training checkpoint.\n",
        "2. Pass the training arguments to [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) along with the model, dataset, tokenizer, data collator, and `compute_metrics` function.\n",
        "3. Call [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train) to finetune your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un_9H93RFMo5"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_imdb[\"train\"],\n",
        "    eval_dataset=tokenized_imdb[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DWzOVyeFMo5"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "[Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) applies dynamic padding by default when you pass `tokenizer` to it. In this case, you don't need to specify a data collator explicitly.\n",
        "\n",
        "</Tip>\n",
        "\n",
        "Once training is completed, share your model to the Hub with the [push_to_hub()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub) method so everyone can use your model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRihJyv2FMo5"
      },
      "outputs": [],
      "source": [
        "# trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yy3C2RBFMo5"
      },
      "source": [
        "<Tip>\n",
        "\n",
        "For a more in-depth example of how to finetune a model for text classification, take a look at the corresponding\n",
        "[PyTorch notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb).\n",
        "\n",
        "</Tip>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1Yaan0dFMo5"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru3m3aetFMo6"
      },
      "source": [
        "Great, now that you've finetuned a model, you can use it for inference!\n",
        "\n",
        "Grab some text you'd like to run inference on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0ygtokPFMo6"
      },
      "outputs": [],
      "source": [
        "text = \"The WI-FI is pretty slow!\"\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "classifier(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pIm_fRSIMr-"
      },
      "outputs": [],
      "source": [
        "text = \"The movie last night was great!\"\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "classifier(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONtpDAOBJ0mC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
